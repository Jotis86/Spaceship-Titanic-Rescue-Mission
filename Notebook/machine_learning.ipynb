{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix, auc\n",
    "from scipy.stats import uniform, randint\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data cleaned in the previous step\n",
    "all_data_df = pd.read_csv(\"C:/Users/juane/OneDrive/Escritorio/Datos/Kaggle_Titanic/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Create new features\n",
    "all_data_df['TotalSpending'] = all_data_df['RoomService'] + all_data_df['FoodCourt'] + all_data_df['ShoppingMall'] + all_data_df['Spa'] + all_data_df['VRDeck']\n",
    "all_data_df['SpendingPerAge'] = all_data_df['TotalSpending'] / (all_data_df['Age'] + 1)  # +1 to avoid division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding for categorical variables\n",
    "one_hot_encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "categorical_columns = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP']\n",
    "encoded_features = one_hot_encoder.fit_transform(all_data_df[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = all_data_df.drop('Transported', axis=1)\n",
    "y = all_data_df['Transported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el escalador\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Ajustar y transformar los datos de entrenamiento\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transformar los datos de prueba\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "svm_clf = SVC(probability=True, random_state=42)\n",
    "knn_clf = KNeighborsClassifier()\n",
    "xgb_clf = XGBClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "log_reg.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for ROC-AUC\n",
    "y_pred_proba_log_reg = log_reg.predict_proba(X_test)[:, 1]\n",
    "y_pred_proba_rf = rf_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred_proba_gb = gb_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred_proba_svm = svm_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred_proba_knn = knn_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred_proba_xgb = xgb_clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "def evaluate_model(y_test, y_pred, y_pred_proba):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "log_reg_metrics = evaluate_model(y_test, y_pred_log_reg, y_pred_proba_log_reg)\n",
    "rf_metrics = evaluate_model(y_test, y_pred_rf, y_pred_proba_rf)\n",
    "gb_metrics = evaluate_model(y_test, y_pred_gb, y_pred_proba_gb)\n",
    "svm_metrics = evaluate_model(y_test, y_pred_svm, y_pred_proba_svm)\n",
    "knn_metrics = evaluate_model(y_test, y_pred_knn, y_pred_proba_knn)\n",
    "xgb_metrics = evaluate_model(y_test, y_pred_xgb, y_pred_proba_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print evaluation metrics\n",
    "print(f\"Logistic Regression: Accuracy={log_reg_metrics[0]:.2f}, Precision={log_reg_metrics[1]:.2f}, Recall={log_reg_metrics[2]:.2f}, F1-Score={log_reg_metrics[3]:.2f}, ROC-AUC={log_reg_metrics[4]:.2f}\")\n",
    "print(f\"Random Forest: Accuracy={rf_metrics[0]:.2f}, Precision={rf_metrics[1]:.2f}, Recall={rf_metrics[2]:.2f}, F1-Score={rf_metrics[3]:.2f}, ROC-AUC={rf_metrics[4]:.2f}\")\n",
    "print(f\"Gradient Boosting: Accuracy={gb_metrics[0]:.2f}, Precision={gb_metrics[1]:.2f}, Recall={gb_metrics[2]:.2f}, F1-Score={gb_metrics[3]:.2f}, ROC-AUC={gb_metrics[4]:.2f}\")\n",
    "print(f\"SVM: Accuracy={svm_metrics[0]:.2f}, Precision={svm_metrics[1]:.2f}, Recall={svm_metrics[2]:.2f}, F1-Score={svm_metrics[3]:.2f}, ROC-AUC={svm_metrics[4]:.2f}\")\n",
    "print(f\"KNN: Accuracy={knn_metrics[0]:.2f}, Precision={knn_metrics[1]:.2f}, Recall={knn_metrics[2]:.2f}, F1-Score={knn_metrics[3]:.2f}, ROC-AUC={knn_metrics[4]:.2f}\")\n",
    "print(f\"XGBoost: Accuracy={xgb_metrics[0]:.2f}, Precision={xgb_metrics[1]:.2f}, Recall={xgb_metrics[2]:.2f}, F1-Score={xgb_metrics[3]:.2f}, ROC-AUC={xgb_metrics[4]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC Curve for the best model - Gradient Boosting\n",
    "best_model = gb_clf\n",
    "y_pred_proba_best = y_pred_proba_gb\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_best)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Precision-Recall Curve for the best model\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba_best)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='blue', lw=2, label=f'Precision-Recall curve (area = {pr_auc:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the confusion matrix\n",
    "def plot_confusion_matrix(y_test, y_pred, title):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "# Generate and plot the confusion matrix for the Gradient Boosting model\n",
    "plot_confusion_matrix(y_test, y_pred_gb, 'Gradient Boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the confusion matrix for the Gradient Boosting model\n",
    "cm_gb = confusion_matrix(y_test, y_pred_gb)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix for Gradient Boosting:\")\n",
    "print(cm_gb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
