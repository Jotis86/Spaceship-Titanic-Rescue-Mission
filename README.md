# 🚀 Spaceship Titanic Rescue Mission 🌌

## 🎯 Objective
Welcome to the year 2912, where data science skills are needed to solve a cosmic mystery. 🌠 Four light-years away, distress signals have been received, and the situation looks dire. 🚨

The Spaceship Titanic, an interstellar passenger liner, was launched a month ago with nearly 13,000 passengers. 🛸 It embarked on its maiden voyage, transporting emigrants from our solar system to three newly habitable exoplanets orbiting nearby stars. 🌍🌟

While orbiting Alpha Centauri en route to its first destination, the scorching 55 Cancri E, the unsuspecting Spaceship Titanic collided with a space-time anomaly hidden within a dust cloud. 🌌 Unfortunately, it met a fate similar to its namesake from 1000 years ago. Although the ship remained intact, nearly half of the passengers were transported to an alternate dimension! 🌀

To assist rescue crews in recovering the lost passengers, you must predict which passengers were transported by the anomaly using the records recovered from the ship's damaged computer system. 💻

This project is part of a Kaggle challenge to help save the passengers and change history! 🏆

## ⚙️ Functionality
- 📥 Data loading and merging
- 🧹 Data cleaning and preprocessing
- 📊 Exploratory data analysis (EDA)
- 🛠️ Feature engineering
- 🤖 Model training and evaluation
- 📈 Visualization of results
- 🌐 Deployment using Streamlit

## 🛠️ Tools Used
- **Python** 🐍: Programming language
- **Pandas** 🐼: Data manipulation
- **NumPy** 🔢: Numerical computations
- **Matplotlib & Seaborn** 📊: Data visualization
- **Scikit-learn** 🤖: Machine learning
- **Streamlit** 🌐: Web app framework

## 🛤️ Development Process
1. **Import Libraries** 📚: Import necessary libraries for data analysis and visualization.
2. **Load Dataset** 📥: Load and merge datasets.
3. **Initial Exploration** 🔍: Display the first few rows and all columns of the combined dataset.
4. **Data Cleaning** 🧹: Handle missing values by filling numerical columns with the mean and categorical columns with the mode.
5. **Outlier Detection** 🚨: Identify outliers using the Interquartile Range (IQR) method.
6. **Exploratory Data Analysis (EDA)** 📊:
   - Distribution of Age 🎂
   - Distribution of Age by HomePlanet 🌍
   - Spending on RoomService, FoodCourt, ShoppingMall, Spa, and VRDeck 💸
   - Age Distribution by Transported Status 🚀
   - Spending on RoomService by HomePlanet 🏨
   - Spending on FoodCourt by Destination 🍽️
   - Spending on Spa by Transported Status 🧖
   - Heatmap of CryoSleep Status by HomePlanet ❄️
   - Stacked Bar Chart of CryoSleep Status by HomePlanet 📊
7. **Correlation Analysis** 🔗: Convert categorical variables to numerical and calculate the correlation matrix.
8. **Feature Engineering** 🛠️: Create new features and apply One-Hot Encoding for categorical variables.
9. **Data Preparation** 📦: Define features and target variable, split the data into training and testing sets, and scale the data.
10. **Model Training and Evaluation** 🤖: Initialize, train, and evaluate models. Plot ROC and Precision-Recall curves, and generate confusion matrices.

## 📊 Results
- Detailed analysis and visualizations of the dataset. 📈
- Identification of key features and their impact on the target variable. 🔍
- Performance metrics of various models, with Gradient Boosting being the best model. 🏆

## 🌐 Streamlit App
The project is deployed as an interactive web application using Streamlit. Users can explore the data, visualize results, and interact with the predictive models. 🌟

## 📁 Project Structure
- App
- Data
- Notebook

## 📞 Contact
For any questions or feedback, please reach out to:
- **Email**: jotaduranbon.com 📧




